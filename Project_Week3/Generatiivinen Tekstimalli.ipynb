{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "144b2aef",
   "metadata": {},
   "source": [
    "## Generatiivinen tekstimalli\n",
    "Tekstiaineistoksi valitsimme kaikki kolme Lord of The Rings -kirjasarjan kirjaa englannin kielellä.\n",
    "Aineistoksi olisi varmasti riittänyt yksikin kirja, tai pieni osa siitä, mutta halusimme selivttää, vaikuttaako aineiston laajuus tekstin järkevyyteen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bfdf5fa-b72c-41e2-9f58-fe30746d2f87",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6bfdf5fa-b72c-41e2-9f58-fe30746d2f87",
    "outputId": "c72217e2-f202-4e9f-88aa-61020cc930a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras version: 3.9.2\n",
      "Keras backend: tensorflow\n",
      "Tensorflow version: 2.19.0\n",
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Setup and imports\n",
    "import os\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'  # You can change to 'jax' or 'torch' if preferred\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras\n",
    "import sentencepiece as spm\n",
    "\n",
    "print(f\"Keras version: {keras.__version__}\")\n",
    "print(f\"Keras backend: {keras.config.backend()}\")\n",
    "print(f\"Tensorflow version: {tf.__version__}\")\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d945eb0c",
   "metadata": {},
   "source": [
    "### Ladataan malli ja generoidaan teksti"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa94de98",
   "metadata": {},
   "source": [
    "Malli on koulutettu eri notebookissa ja tallennettu."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a11622b",
   "metadata": {},
   "source": [
    "Ladataan malli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48d49d44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load saved model\n",
    "model = keras.models.load_model('LotR_trilogy_best_model.keras')\n",
    "# Load SentencePiece tokenizer\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load('Lotr_trilogy_sp.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62eb512",
   "metadata": {},
   "source": [
    "Tekstin generointifunktio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a998c8d3-bb56-4f56-b5a2-cac6275fd26f",
   "metadata": {
    "id": "a998c8d3-bb56-4f56-b5a2-cac6275fd26f"
   },
   "outputs": [],
   "source": [
    "seq_length = 64\n",
    "def generate_text(model, sp, prompt, num_tokens=100, temperature=1.0):\n",
    "    \"\"\"Generate text based on a prompt with proper lowercase handling.\"\"\"\n",
    "    # Convert prompt to lowercase to match training data\n",
    "    lowercase_prompt = prompt#.lower()\n",
    "\n",
    "    # Encode the prompt\n",
    "    input_ids = sp.encode_as_ids(lowercase_prompt)\n",
    "\n",
    "    # Rest of your generation code stays the same...\n",
    "    if len(input_ids) < seq_length:\n",
    "        padding_length = seq_length - len(input_ids)\n",
    "        input_ids = [0] * padding_length + input_ids\n",
    "    else:\n",
    "        padding_length = 0\n",
    "        input_ids = input_ids[-seq_length:]\n",
    "\n",
    "    # Generated tokens\n",
    "    generated_ids = list(input_ids[padding_length:])\n",
    "\n",
    "    # Generate text token by token\n",
    "    for _ in range(num_tokens):\n",
    "        x = np.array([input_ids])\n",
    "        predictions = model.predict(x, verbose=0)[0]\n",
    "        logits = predictions[-1]\n",
    "        logits = logits / temperature\n",
    "        exp_logits = np.exp(logits - np.max(logits))\n",
    "        probs = exp_logits / np.sum(exp_logits)\n",
    "        next_token = np.random.choice(len(probs), p=probs)\n",
    "        generated_ids.append(next_token)\n",
    "        input_ids = input_ids[1:] + [next_token]\n",
    "\n",
    "    # Decode the generated sequence\n",
    "    generated_text = sp.decode(generated_ids)\n",
    "\n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1c18b5",
   "metadata": {},
   "source": [
    "Generoidaan hieman tekstiä"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9580493-d3a5-4cfc-9943-fe99dcb8e01d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d9580493-d3a5-4cfc-9943-fe99dcb8e01d",
    "outputId": "3489ff49-3d77-4f36-f73a-65a9a47324b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt: Gandalf was feeling depressed and alone. He had lost his staff. He had lost his way. He had lost his mind.\n",
      "Gandalf was feeling depressed and alone. He had lost his staff. He had lost his way. He had lost his mind. The ring now went off again, and he was now feeling very wretched. He was hard and rather dismal. He missed Pippin, and felt sleep they made their way. All hours passed without being followed at night! We've got to begin with this laid hold of the Ring, and you know the way well. I wonder what sort of dreams they are having.' They went round to the other side. They had not long to breathe, and yet passing away beyond his sight into the hollow,\n",
      "\n",
      "Prompt: Frodo was drinking coffee with Sam. They were discussing the weather. It was a sunny day.\n",
      "Frodo was drinking coffee with Sam. They were discussing the weather. It was a sunny day. The was a flood. 'It may be helped,' said Gandalf. 'We shall need your help, and the help of anything that will not be set in this place. And anyway I have a help of any bad news. I have done my best now. I am not sure that I want to come out into the open yet.' They had been half dreaming, and because they said no more, an orc-chieftain. One or owyn went with Beregond and Merry followed Faramir. Pippin proved now\n",
      "\n",
      "Prompt: Aragorn was in the woods. He was hunting for orcs. He was hungry and tired.\n",
      "Aragorn was in the woods. He was hunting for orcs. He was hungry and tired. Their legs were long, and they were very more than a dusk, about the hour of sunset. 'Come! ' Frodo bore me back.' Then he disappeared, and sat up beside Sam, who was now grinning. 'I don't deny it, but I'll never believe you are sleeping again, whether you snore or not. I shall kick you hard to make sure. 'You are a set of deceitful scoundrels!' he said, turning to the others. 'But bless you!'\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: Generate sample text\n",
    "prompts = [\n",
    "    \"Gandalf was feeling depressed and alone. He had lost his staff. He had lost his way. He had lost his mind.\",\n",
    "    \"Frodo was drinking coffee with Sam. They were discussing the weather. It was a sunny day.\",\n",
    "    \"Aragorn was in the woods. He was hunting for orcs. He was hungry and tired.\",\n",
    "]\n",
    "\n",
    "for prompt in prompts:\n",
    "    print(f\"\\nPrompt: {prompt}\")\n",
    "    generated = generate_text(model, sp, prompt, num_tokens=100, temperature=1.2)\n",
    "    print(generated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58aa7e1",
   "metadata": {},
   "source": [
    "Generoitu teksti ei muodosta kovin järkevää tarinaa, mutta viereiset lauseet näyttävät usein liittyvän toisiinsa jonkin verran.\n",
    "\n",
    "Koko kirjasarjan syöttö ei ilmeisesti vaikuttanut tarpeeksi."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "NEURO",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
